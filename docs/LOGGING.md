# Logging System Documentation

## Overview

AskRivo includes a comprehensive logging system that tracks all application activity including API requests, LLM interactions, tool calls, user messages, and performance metrics.

## Log Levels

| Level | Purpose | Example Use Cases |
|-------|---------|-------------------|
| `DEBUG` | Detailed diagnostic information | Tool calls, tool results, internal state |
| `INFO` | General informational messages | API requests, model selection, user messages |
| `WARN` | Warning messages for potential issues | Deprecated features, unusual inputs |
| `ERROR` | Error messages for failures | API errors, tool failures, exceptions |

## Log Location

### Development (Node.js Runtime)
- **Location**: `logs/` folder in project root
- **Format**: `app-YYYY-MM-DD.log` (daily rotation)
- **Example**: `logs/app-2025-12-14.log`

### Production (Edge Runtime)
- **Location**: Console output only (Edge runtime doesn't support file system)
- **Access**: View logs in Vercel dashboard or deployment logs

## Log Entry Format

Each log entry includes:

```
[TIMESTAMP] [LEVEL] [CATEGORY] Message
Data: { ... JSON data ... }
Error: { ... error details ... }
---
```

### Example Log Entry

```
[2025-12-14T14:30:45.123Z] [INFO] [API_REQUEST] Incoming request to /api/chat
Data: {
  "messageCount": 3,
  "lastMessage": "I make 20k AED a month and want to buy in Marina for 2M"
}
---
```

## Logging Categories

### API_REQUEST
Logs incoming HTTP requests to API routes.

**Data includes**:
- Message count
- Last message preview
- Request metadata

### API_RESPONSE
Logs HTTP responses from API routes.

**Data includes**:
- Status code
- Response duration
- Error details (if any)

### MODEL_SELECTION
Logs which LLM model is being used.

**Data includes**:
- Provider (openai/mistral)
- Model name (gpt-5-mini, gpt-5.2, etc.)

### LLM_REQUEST
Logs requests sent to LLM providers.

**Data includes**:
- Provider and model
- Message count
- Temperature setting
- Available tools

### LLM_RESPONSE
Logs responses received from LLM providers.

**Data includes**:
- Provider and model
- Response metadata
- Token usage (if available)

### TOOL_CALL
Logs when a tool/function is invoked.

**Data includes**:
- Tool name
- Input parameters
- Timestamp

### TOOL_RESULT
Logs the result of a tool/function execution.

**Data includes**:
- Tool name
- Output data
- Success/failure status

### USER_MESSAGE
Logs messages sent by users.

**Data includes**:
- Message ID
- Message content
- Timestamp

### ASSISTANT_MESSAGE
Logs messages generated by the AI assistant.

**Data includes**:
- Message ID
- Message content
- Timestamp

### PERFORMANCE
Logs performance metrics for operations.

**Data includes**:
- Operation name
- Duration in milliseconds
- Additional context

### API_ERROR
Logs errors that occur during API processing.

**Data includes**:
- Error message
- Stack trace
- Request context
- Duration before failure

## Usage Examples

### Basic Logging

```typescript
import { logger } from '@/lib/logger';

// Debug message
logger.debug('CATEGORY', 'Debug message', { someData: 'value' });

// Info message
logger.info('CATEGORY', 'Info message', { someData: 'value' });

// Warning message
logger.warn('CATEGORY', 'Warning message', { someData: 'value' });

// Error message
logger.error('CATEGORY', 'Error message', error, { someData: 'value' });
```

### Specialized Logging Methods

```typescript
// Log API request
logger.apiRequest('/api/chat', { messageCount: 5 });

// Log API response
logger.apiResponse('/api/chat', 200, { duration: 1234 });

// Log LLM request
logger.llmRequest('openai', 'gpt-5-mini', { temperature: 0 });

// Log LLM response
logger.llmResponse('openai', 'gpt-5-mini', { tokens: 150 });

// Log tool call
logger.toolCall('calculate_emi', { loan_amount: 1000000 });

// Log tool result
logger.toolResult('calculate_emi', { monthly_emi: 5500 });

// Log user message
logger.userMessage('msg-123', 'I want to buy a house');

// Log assistant message
logger.assistantMessage('msg-124', 'Let me help you with that');

// Log performance metric
logger.performanceMetric('API /api/chat', 1234);

// Log model switch
logger.modelSwitch('gpt-4-turbo', 'gpt-5-mini', 'Performance optimization');
```

## Current Logging Coverage

### API Route (`/api/chat`)
✅ Incoming requests  
✅ User messages  
✅ LLM requests  
✅ Model selection  
✅ Tool invocations (all 4 tools)  
✅ Tool results  
✅ Performance metrics  
✅ API responses  
✅ Error handling  

### Tools
✅ `calculate_emi` - Parameters and results logged  
✅ `calculate_upfront_costs` - Parameters and results logged  
✅ `calculate_max_loan` - Parameters and results logged  
✅ `compare_rent_vs_buy` - Parameters and results logged  

## Viewing Logs

### Development (Local)

1. Start the dev server: `npm run dev`
2. Use the application
3. Check `logs/app-YYYY-MM-DD.log` for detailed logs
4. Also check console output for real-time logs

### Production (Vercel)

1. Go to Vercel dashboard
2. Select your project
3. Click on "Logs" tab
4. View real-time console logs

## Log Analysis

### Finding Specific Events

```bash
# Find all tool calls
grep "TOOL_CALL" logs/app-2025-12-14.log

# Find all errors
grep "ERROR" logs/app-2025-12-14.log

# Find performance issues (>2000ms)
grep "PERFORMANCE" logs/app-2025-12-14.log | grep -E "[2-9][0-9]{3}ms"

# Find specific user messages
grep "USER_MESSAGE" logs/app-2025-12-14.log
```

### Performance Analysis

Look for `PERFORMANCE` entries to identify slow operations:

```
[2025-12-14T14:30:45.123Z] [DEBUG] [PERFORMANCE] API /api/chat took 1234ms
```

If duration > 2000ms, investigate:
- LLM response time
- Tool execution time
- Network latency

## Troubleshooting

### Logs Not Being Created

**Issue**: `logs/` folder doesn't exist or files aren't being created.

**Solution**:
1. Check if you're using Edge runtime (file system not supported)
2. Switch to Node.js runtime in `app/api/chat/route.ts`:
   ```typescript
   export const runtime = 'nodejs'; // Change from 'edge'
   ```
3. Restart the dev server

### Logs Too Verbose

**Issue**: Too many DEBUG logs cluttering output.

**Solution**: Modify logger to filter by level:
```typescript
// In lib/logger.ts, add level filtering
if (level === 'DEBUG' && process.env.LOG_LEVEL !== 'DEBUG') {
  return; // Skip debug logs unless explicitly enabled
}
```

### Missing Tool Results

**Issue**: Tool calls logged but results missing.

**Solution**: Check for errors in tool execution. Look for ERROR logs around the same timestamp.

## Best Practices

1. **Use appropriate log levels**
   - DEBUG: Internal details, tool calls
   - INFO: Normal operations, user actions
   - WARN: Unusual but handled situations
   - ERROR: Failures requiring attention

2. **Include context in data**
   - Always include relevant IDs (message ID, user ID, etc.)
   - Include input parameters for debugging
   - Include timing information for performance analysis

3. **Don't log sensitive data**
   - Never log API keys
   - Sanitize user personal information
   - Truncate long messages if needed

4. **Monitor log file size**
   - Daily rotation prevents files from growing too large
   - Consider implementing log cleanup for old files
   - In production, use proper log aggregation (Vercel logs, CloudWatch, etc.)

## Future Enhancements

Potential improvements:
- Log rotation and cleanup
- Log aggregation service integration (Datadog, LogRocket, etc.)
- Structured JSON logging for easier parsing
- Log level configuration via environment variable
- Request ID tracking across multiple operations
- User session tracking
- Cost tracking (LLM token usage)

## Environment Variables

Add these to `.env.local` for log configuration:

```env
# Log level: DEBUG, INFO, WARN, ERROR
LOG_LEVEL=DEBUG

# Enable file logging (requires Node.js runtime)
ENABLE_FILE_LOGGING=true
```

## Security Considerations

- Logs may contain user conversations - ensure proper access control
- Don't commit log files to version control (already in `.gitignore`)
- In production, ensure logs are stored securely
- Consider GDPR/privacy requirements for user data in logs
- Implement log retention policies

## Support

For issues with logging:
1. Check console output first
2. Verify runtime configuration (edge vs nodejs)
3. Check file permissions for `logs/` folder
4. Review error logs for logger failures
